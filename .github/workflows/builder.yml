name: Build node-llama-cpp addons
on:
  workflow_dispatch:
  push:
    branches: [ builder ]
jobs:
  windows-cuda:
    runs-on: windows-2019
    strategy:
      matrix:
        cuda_version: ['11.8.0', '12.4.1', '12.2.0']
        include:
          - cuda_version: '11.8.0'
            optimized: 'windows-cuda-1180'
          - cuda_version: '12.4.1'
            optimized: 'windows-cuda-1241'
          - cuda_version: '12.2.0'
            optimized: 'windows-cuda-1220'
    outputs:
      llama-tag: ${{ steps.extract-tag.outputs.tag }}
    steps:
      - name: Clone node-llama-cpp repository
        uses: actions/checkout@v4
        with:
          repository: RaimundoLai/node-llama-cpp
          branch: master
          
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
          
      - name: Add msbuild to PATH
        uses: microsoft/setup-msbuild@v2
        
      - name: Install dependencies
        run: |
          choco install cmake -y
          npm install -g cmake-js
          npm install tar
          
      - name: Install CUDA Toolkit
        uses: Jimver/cuda-toolkit@v0.2.22
        id: cuda-toolkit
        with:
          cuda: ${{ matrix.cuda_version }}
          method: 'network'
          sub-packages: '["nvcc", "cudart", "cublas", "cublas_dev", "thrust", "visual_studio_integration"]'
          
      - name: Build
        shell: powershell
        run: |
          npm ci
          npm run build
          node ./dist/cli/cli.js source download --release latest --skipBuild --noBundle --noUsageExample --updateBinariesReleaseMetadataAndSaveGitBundle
          node ./dist/cli/cli.js source build --ciMode --noUsageExample --arch x64 --nodeTarget 20 --gpu cuda
          
      - name: Find build directory and package
        shell: bash
        run: |
          npx zx -y <<'EOF'
          #!/usr/bin/env zx
          
          // Find build directory
          const buildDirs = await glob('./llama/localBuilds/win-x64-release-*', { onlyDirectories: true });
          
          if (buildDirs.length === 0) {
            console.error('Build directory not found');
            process.exit(1);
          }
          
          const buildDir = buildDirs[0];
          const buildDirName = path.basename(buildDir);
          const releasePath = path.join(buildDir, 'Release');
          
          console.log(`Found build directory: ${buildDirName}`);
          
          // Check if Release directory exists
          if (!await fs.pathExists(releasePath)) {
            console.error(`Release directory not found at: ${releasePath}`);
            process.exit(1);
          }
          
          console.log(`Release directory confirmed at: ${releasePath}`);
          
          // Set environment variables
          await $`echo "BUILD_DIR_NAME=${buildDirName}" >> ${process.env.GITHUB_ENV}`;
          await $`echo "RELEASE_PATH=${releasePath}" >> ${process.env.GITHUB_ENV}`;
          EOF
          
      - name: Extract llama.cpp tag from build directory
        id: extract-tag
        shell: bash
        run: |
          npx zx -y <<'EOF'
          #!/usr/bin/env zx
          
          const buildDirName = process.env.BUILD_DIR_NAME;
          const tag = buildDirName.replace('win-x64-release-', '');
          
          console.log(`Extracted llama.cpp tag: ${tag}`);
          
          await $`echo "tag=${tag}" >> ${process.env.GITHUB_OUTPUT}`;
          await $`echo "LLAMA_TAG=${tag}" >> ${process.env.GITHUB_ENV}`;
          EOF
          
      - name: Create tar.gz archive
        shell: bash
        run: |
          npx zx -y <<'EOF'
          #!/usr/bin/env zx
          
          const archiveName = '${{ matrix.optimized }}.tar.gz';
          const releasePath = process.env.RELEASE_PATH;
          
          console.log(`Creating archive: ${archiveName}`);
          console.log(`From directory: ${releasePath}`);
          
          // Create tar.gz archive
          await $`tar -czf ${archiveName} -C ${releasePath} .`;
          
          console.log(`Archive created successfully: ${archiveName}`);
          
          await $`echo "ARCHIVE_NAME=${archiveName}" >> ${process.env.GITHUB_ENV}`;
          EOF
          
      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: ${{ matrix.optimized }}
          path: ${{ env.ARCHIVE_NAME }}
          
  windows-no-cuda:
    runs-on: windows-2019
    outputs:
      llama-tag: ${{ steps.extract-tag.outputs.tag }}
    steps:
      - name: Clone node-llama-cpp repository
        uses: actions/checkout@v4
        with:
          repository: RaimundoLai/node-llama-cpp
          branch: master
          
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
          
      - name: Add msbuild to PATH
        uses: microsoft/setup-msbuild@v2
          
      - name: Install dependencies
        run: |
          choco install cmake -y
          npm install -g cmake-js
          npm install tar

      - name: Build
        shell: powershell
        run: |
          npm ci
          npm run build
          node ./dist/cli/cli.js source download --release latest --skipBuild --noBundle --noUsageExample --updateBinariesReleaseMetadataAndSaveGitBundle
          node ./dist/cli/cli.js source build --ciMode --noUsageExample --arch x64 --nodeTarget 20 --gpu false
          
      - name: Find build directory and package
        shell: bash
        run: |
          npx zx -y <<'EOF'
          #!/usr/bin/env zx
          
          // Find build directory
          const buildDirs = await glob('./llama/localBuilds/win-x64-release-*', { onlyDirectories: true });
          
          if (buildDirs.length === 0) {
            console.error('Build directory not found');
            process.exit(1);
          }
          
          const buildDir = buildDirs[0];
          const buildDirName = path.basename(buildDir);
          const releasePath = path.join(buildDir, 'Release');
          
          console.log(`Found build directory: ${buildDirName}`);
          
          // Check if Release directory exists
          if (!await fs.pathExists(releasePath)) {
            console.error(`Release directory not found at: ${releasePath}`);
            process.exit(1);
          }
          
          console.log(`Release directory confirmed at: ${releasePath}`);
          
          // Set environment variables
          await $`echo "BUILD_DIR_NAME=${buildDirName}" >> ${process.env.GITHUB_ENV}`;
          await $`echo "RELEASE_PATH=${releasePath}" >> ${process.env.GITHUB_ENV}`;
          EOF
          
      - name: Extract llama.cpp tag from build directory
        id: extract-tag
        shell: bash
        run: |
          npx zx -y <<'EOF'
          #!/usr/bin/env zx
          
          const buildDirName = process.env.BUILD_DIR_NAME;
          const tag = buildDirName.replace('win-x64-release-', '');
          
          console.log(`Extracted llama.cpp tag: ${tag}`);
          
          await $`echo "tag=${tag}" >> ${process.env.GITHUB_OUTPUT}`;
          await $`echo "LLAMA_TAG=${tag}" >> ${process.env.GITHUB_ENV}`;
          EOF
          
      - name: Create tar.gz archive
        shell: bash
        run: |
          npx zx -y <<'EOF'
          #!/usr/bin/env zx
          
          const archiveName = 'windows-no-cuda.tar.gz';
          const releasePath = process.env.RELEASE_PATH;
          
          console.log(`Creating archive: ${archiveName}`);
          console.log(`From directory: ${releasePath}`);
          
          // Create tar.gz archive
          await $`tar -czf ${archiveName} -C ${releasePath} .`;
          
          console.log(`Archive created successfully: ${archiveName}`);
          
          await $`echo "ARCHIVE_NAME=${archiveName}" >> ${process.env.GITHUB_ENV}`;
          EOF
          
      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: windows-no-cuda
          path: ${{ env.ARCHIVE_NAME }}

  create-update-release:
    needs: [windows-cuda, windows-no-cuda]
    runs-on: ubuntu-latest
    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts
          
      - name: List artifacts
        run: ls -R artifacts/
        
      - name: Get llama.cpp tag
        id: llama-tag
        run: |
          # 從 windows-cuda job 獲取 llama tag（所有 job 應該使用相同版本）
          LLAMA_TAG="${{ needs.windows-cuda.outputs.llama-tag }}"
          echo "Using llama.cpp tag: $LLAMA_TAG"
          echo "tag=$LLAMA_TAG" >> $GITHUB_OUTPUT
          
      - name: Get current date
        id: date
        run: echo "date=$(date +'%Y%m%d-%H%M%S')" >> $GITHUB_OUTPUT
        
      - name: Create llama.cpp Tagged Release
        uses: softprops/action-gh-release@v1
        if: github.event_name != 'pull_request'
        with:
          tag_name: llama-${{ steps.llama-tag.outputs.tag }}
          name: node-llama-cpp builds (llama.cpp ${{ steps.llama-tag.outputs.tag }})
          body: |
            node-llama-cpp addon builds based on llama.cpp ${{ steps.llama-tag.outputs.tag }}
            Build date: ${{ steps.date.outputs.date }}
            
            **Available builds:**
            - Windows with CUDA 11.8.0 support
            - Windows with CUDA 12.2.0 support  
            - Windows with CUDA 12.4.1 support
            - Windows without CUDA support
            
            **Installation:**
            Extract the tar.gz file to your node-llama-cpp installation directory.
          files: |
            artifacts/**/*.tar.gz
          draft: false
          prerelease: false
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          
      - name: Update Latest Release
        uses: softprops/action-gh-release@v1
        if: github.event_name != 'pull_request'
        with:
          tag_name: latest
          name: Latest node-llama-cpp builds
          body: |
            Latest node-llama-cpp addon builds.
            Based on llama.cpp: ${{ steps.llama-tag.outputs.tag }}
            Last updated: ${{ steps.date.outputs.date }}
            
            **Available builds:**
            - Windows with CUDA 11.8.0 support
            - Windows with CUDA 12.2.0 support
            - Windows with CUDA 12.4.1 support  
            - Windows without CUDA support
            
            **Installation:**
            Extract the tar.gz file to your node-llama-cpp installation directory.
          files: |
            artifacts/**/*.tar.gz
          draft: false
          prerelease: false
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}