name: Build node-llama-cpp addons
on:
  workflow_dispatch:
  push:
    branches: [ builder ]
jobs:
  windows-cuda:
    runs-on: windows-2019
    strategy:
      matrix:
        cuda_version: ['11.8.0', '12.4.1', '12.2.0']
        include:
          - cuda_version: '11.8.0'
            optimized: 'windows-cuda-1180'
          - cuda_version: '12.4.1'
            optimized: 'windows-cuda-1241'
          - cuda_version: '12.2.0'
            optimized: 'windows-cuda-1220'
    steps:
      - name: Clone node-llama-cpp repository
        uses: actions/checkout@v4
        with:
          repository: RaimundoLai/node-llama-cpp
          branch: master
          
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
          
      - name: Add msbuild to PATH
        uses: microsoft/setup-msbuild@v2
        
      - name: Install dependencies
        run: |
          choco install cmake -y
          npm install -g cmake-js
          npm install tar
          
      - name: Install CUDA Toolkit
        uses: Jimver/cuda-toolkit@v0.2.22
        id: cuda-toolkit
        with:
          cuda: ${{ matrix.cuda_version }}
          method: 'network'
          sub-packages: '["nvcc", "cudart", "cublas", "cublas_dev", "thrust", "visual_studio_integration"]'
          
      - name: Build
        shell: powershell
        run: |
          npm ci
          npm run build
          node ./dist/cli/cli.js source download --release latest --skipBuild --noBundle --noUsageExample --updateBinariesReleaseMetadataAndSaveGitBundle
          node ./dist/cli/cli.js source build --ciMode --noUsageExample --arch x64 --nodeTarget 20 --gpu cuda
          
      - name: Find build directory and package
        shell: bash
        run: |
          npx zx -y <<'EOF'
          #!/usr/bin/env zx
          
          const localBuildsDirectoryPath = path.join(process.cwd(), "llama", "localBuilds");
          
          // Find win-x64 directory in localBuilds
          const buildDirs = await glob('./llama/localBuilds/win-x64*', { onlyDirectories: true });
          
          if (buildDirs.length === 0) {
            console.error('Build directory not found');
            process.exit(1);
          }
          
          const buildDir = buildDirs[0];
          console.log(`Found build directory: ${buildDir}`);
          
          // Check if Release directory exists
          const releasePath = path.join(buildDir, 'Release');
          console.log(`Checking Release directory: ${releasePath}`);
          
          if (!(await fs.pathExists(releasePath))) {
            console.error('Release directory not found');
            process.exit(1);
          }
          
          // Create bins directory similar to node-llama-cpp logic
          const llamaBinsDirectoryPath = path.join(process.cwd(), "bins");
          await fs.ensureDir(llamaBinsDirectoryPath);
          
          // Get folder name from build directory
          const folderName = path.basename(buildDir);
          console.log(`Moving Release contents from ${releasePath} to bins/${folderName}`);
          
          // Move Release directory content to bins/folderName
          await fs.move(releasePath, path.join(llamaBinsDirectoryPath, folderName));
          
          // Set environment variables
          await $`echo "BINS_PATH=${llamaBinsDirectoryPath}" >> ${process.env.GITHUB_ENV}`;
          await $`echo "FOLDER_NAME=${folderName}" >> ${process.env.GITHUB_ENV}`;
          EOF
          
      - name: Create tar.gz archive
        shell: bash
        run: |
          npx zx -y <<'EOF'
          #!/usr/bin/env zx
          
          const archiveName = '${{ matrix.optimized }}.tar.gz';
          const binsPath = process.env.BINS_PATH;
          const folderName = process.env.FOLDER_NAME;
          const targetPath = path.join(binsPath, folderName);
          
          console.log(`Creating archive: ${archiveName}`);
          console.log(`From directory: ${targetPath}`);
          
          // Create tar.gz archive from the specific folder in bins
          await $`tar -czf ${archiveName} -C ${targetPath} .`;
          
          console.log(`Archive created successfully: ${archiveName}`);
          
          await $`echo "ARCHIVE_NAME=${archiveName}" >> ${process.env.GITHUB_ENV}`;
          EOF
          
      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: ${{ matrix.optimized }}
          path: ${{ env.ARCHIVE_NAME }}
          
  windows-no-cuda:
    runs-on: windows-2019
    steps:
      - name: Clone node-llama-cpp repository
        uses: actions/checkout@v4
        with:
          repository: RaimundoLai/node-llama-cpp
          branch: master
          
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
          
      - name: Add msbuild to PATH
        uses: microsoft/setup-msbuild@v2
          
      - name: Install dependencies
        run: |
          choco install cmake -y
          npm install -g cmake-js
          npm install tar

      - name: Build
        shell: powershell
        run: |
          npm ci
          npm run build
          node ./dist/cli/cli.js source download --release latest --skipBuild --noBundle --noUsageExample --updateBinariesReleaseMetadataAndSaveGitBundle
          node ./dist/cli/cli.js source build --ciMode --noUsageExample --arch x64 --nodeTarget 20 --gpu false
          
      - name: Find build directory and package
        shell: bash
        run: |
          npx zx -y <<'EOF'
          #!/usr/bin/env zx
          
          const localBuildsDirectoryPath = path.join(process.cwd(), "llama", "localBuilds");
          
          // Find win-x64 directory in localBuilds
          const buildDirs = await glob('./llama/localBuilds/win-x64*', { onlyDirectories: true });
          
          if (buildDirs.length === 0) {
            console.error('Build directory not found');
            process.exit(1);
          }
          
          const buildDir = buildDirs[0];
          console.log(`Found build directory: ${buildDir}`);
          
          // Check if Release directory exists
          const releasePath = path.join(buildDir, 'Release');
          console.log(`Checking Release directory: ${releasePath}`);
          
          if (!(await fs.pathExists(releasePath))) {
            console.error('Release directory not found');
            process.exit(1);
          }
          
          // Create bins directory similar to node-llama-cpp logic
          const llamaBinsDirectoryPath = path.join(process.cwd(), "bins");
          await fs.ensureDir(llamaBinsDirectoryPath);
          
          // Get folder name from build directory
          const folderName = path.basename(buildDir);
          console.log(`Moving Release contents from ${releasePath} to bins/${folderName}`);
          
          // Move Release directory content to bins/folderName
          await fs.move(releasePath, path.join(llamaBinsDirectoryPath, folderName));
          
          // Set environment variables
          await $`echo "BINS_PATH=${llamaBinsDirectoryPath}" >> ${process.env.GITHUB_ENV}`;
          await $`echo "FOLDER_NAME=${folderName}" >> ${process.env.GITHUB_ENV}`;
          EOF
          
      - name: Create tar.gz archive
        shell: bash
        run: |
          npx zx -y <<'EOF'
          #!/usr/bin/env zx
          
          const archiveName = 'windows-no-cuda.tar.gz';
          const binsPath = process.env.BINS_PATH;
          const folderName = process.env.FOLDER_NAME;
          const targetPath = path.join(binsPath, folderName);
          
          console.log(`Creating archive: ${archiveName}`);
          console.log(`From directory: ${targetPath}`);
          
          // Create tar.gz archive from the specific folder in bins
          await $`tar -czf ${archiveName} -C ${targetPath} .`;
          
          console.log(`Archive created successfully: ${archiveName}`);
          
          await $`echo "ARCHIVE_NAME=${archiveName}" >> ${process.env.GITHUB_ENV}`;
          EOF
          
      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: windows-no-cuda
          path: ${{ env.ARCHIVE_NAME }}

  create-update-release:
    needs: [windows-cuda, windows-no-cuda]
    runs-on: ubuntu-latest
    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts
          
      - name: List artifacts
        run: ls -R artifacts/
        
      - name: Get current date
        id: date
        run: echo "date=$(date +'%Y%m%d-%H%M%S')" >> $GITHUB_OUTPUT
        
      - name: Create timestamped Release
        uses: softprops/action-gh-release@v1
        if: github.event_name != 'pull_request'
        with:
          tag_name: build-${{ steps.date.outputs.date }}
          name: node-llama-cpp builds (${{ steps.date.outputs.date }})
          body: |
            node-llama-cpp addon builds
            Build date: ${{ steps.date.outputs.date }}
            
            **Available builds:**
            - Windows with CUDA 11.8.0 support
            - Windows with CUDA 12.2.0 support  
            - Windows with CUDA 12.4.1 support
            - Windows without CUDA support
            
            **Installation:**
            Extract the tar.gz file to your node-llama-cpp installation directory.
          files: |
            artifacts/**/*.tar.gz
          draft: false
          prerelease: false
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          
      - name: Update Latest Release
        uses: softprops/action-gh-release@v1
        if: github.event_name != 'pull_request'
        with:
          tag_name: latest
          name: Latest node-llama-cpp builds
          body: |
            Latest node-llama-cpp addon builds.
            Last updated: ${{ steps.date.outputs.date }}
            
            **Available builds:**
            - Windows with CUDA 11.8.0 support
            - Windows with CUDA 12.2.0 support
            - Windows with CUDA 12.4.1 support  
            - Windows without CUDA support
            
            **Installation:**
            Extract the tar.gz file to your node-llama-cpp installation directory.
          files: |
            artifacts/**/*.tar.gz
          draft: false
          prerelease: false
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}